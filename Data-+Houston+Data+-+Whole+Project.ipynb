{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Project: Wrangle OSM Data to SQL- Houston, Texas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I chose my hometown of Houston, Texas. I originally chose a small area containing Rice University and the museum district then moved my way to the larger metropolitan area. As the data covers a large area, I was unable to efficiently run my code on the full dataset and instead chose to sample the area using code provided by Udacity. I used the code provided and created during the Problem Set exercises as the basis for collecting and auditing the data. From there, I created the csv files and database (which proved to be one of the most difficult parts). I then used the sample project as a template for formulating questions for querying using sqlite. \n",
    "\n",
    "OSM query: \n",
    "https://www.openstreetmap.org/relation/2688911\n",
    "\n",
    "Example project: \n",
    "https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note, several of these import statements appear later as well. This is only to keep track of relevant code \n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re \n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import os\n",
    "import pandas as pd \n",
    "import sqlite3\n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Parsing to find all unique tag names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'node': 278542, 'nd': 348101, 'member': 2515, 'tag': 188029, 'relation': 224, 'way': 41283, 'osm': 1})\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "        osm_file = open(filename, \"r\")\n",
    "        tag_types = defaultdict(int)\n",
    "        for event, elem in ET.iterparse(osm_file):\n",
    "            tag_type = elem.tag\n",
    "            if tag_type not in tag_types.keys(): \n",
    "                tag_types[tag_type] = 1 \n",
    "            else: tag_types[tag_type] += 1 \n",
    "        return tag_types\n",
    "\n",
    "def test():\n",
    "    tags = count_tags('interpreter.osm')\n",
    "    pprint(tags)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit Street names/Ways: Problematic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemchars': 0, 'lower': 93927, 'other': 3910, 'lower_colon': 90192}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Checking tags and K values for problematic characters \n",
    "\"\"\"\n",
    "Uses 3 regular expressions to check for certain patterns in the tags. \n",
    "We would like to change the data from the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "\n",
    "Four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "\"\"\"\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if re.search(lower, k): \n",
    "            keys[\"lower\"] += 1 \n",
    "        elif re.search(lower_colon, k): \n",
    "            keys[\"lower_colon\"] += 1 \n",
    "        elif re.search(problemchars, k): \n",
    "            keys[\"problemchars\"] += 1\n",
    "            print \"problemchars = \", element.tag, element.attrib\n",
    "        else: \n",
    "            keys[\"other\"] += 1 \n",
    "        pass\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "def test():\n",
    "    keys = process_map('interpreter.osm')\n",
    "    print(keys)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Street Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the below code and comments were taken from the problem set prior to this project. I ran the code repeatedly to better understand the types of street names that would be caught and adjusted accordingly. Some streets had programatic fixes while others just needed a very specific one-off fix. While a bit tedious, this approach worked for this data set but may not have worked for a larger one. \n",
    "\n",
    "If needed, the code could be rewritten to search through each word in a street name rather than just the street type (which I believe was a suggestion on the Udacity forums). I thought it sufficient to look for incorrect/mispelled street types rather than the various ways one could write a street type. For my purposes, I saw no reason to go into the details of modifying and standardizing the highway names and types, especially with data that is put together by users and would likely have similar discrepancies in other cities' datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1093': set(['F.M. 1093', 'Farm to Market 1093']),\n",
      " '1464': set(['FM 1464']),\n",
      " '1485': set(['FM 1485']),\n",
      " '1640': set(['FM 1640']),\n",
      " '2920': set(['FM 2920']),\n",
      " '362': set(['FM 362']),\n",
      " '529': set(['Farm To Market Rd 529']),\n",
      " '7A': set(['Fondren Road # 7A']),\n",
      " '90': set(['US 90']),\n",
      " 'A': set(['Dallas St #A']),\n",
      " 'Ave': set(['E Parkwood Ave']),\n",
      " 'B': set(['Richmond Ave, Ste B']),\n",
      " 'Bailey': set(['Bailey']),\n",
      " 'Blvd': set(['Post Oak Blvd']),\n",
      " 'Dr.': set(['Palomar Valley Dr.']),\n",
      " 'Driscoll': set(['Driscoll']),\n",
      " 'Durham': set(['Durham']),\n",
      " 'E': set(['Avenue E', 'FM 646 Rd E', 'North Sam Houston Pkwy E']),\n",
      " 'F': set(['San Felipe Road, suite F']),\n",
      " 'Gulfcrest': set(['Gulfcrest']),\n",
      " 'I-45': set(['I-45']),\n",
      " 'Larchmont': set(['Larchmont']),\n",
      " 'Rd': set(['Cypress North Houston Rd', 'Kuykendahl Rd', 'Rogerdale Rd']),\n",
      " 'S': set(['Highway 6 S']),\n",
      " 'S.': set(['Hwy 6 S.']),\n",
      " 'St': set(['Canal St', 'Tuam St']),\n",
      " 'St.': set(['10039 Bissonnet St.']),\n",
      " 'St.,': set(['10039 Bissonnet St.,']),\n",
      " 'Welford': set(['Welford'])}\n",
      "Driscoll Street\n",
      "Driscoll => Driscoll Street\n",
      "FM 2920 => FM 2920\n",
      "10039 Bissonnet Street\n",
      "10039 Bissonnet St. => 10039 Bissonnet Street\n",
      "Kuykendahl Road\n",
      "Kuykendahl Rd => Kuykendahl Road\n",
      "Cypress North Houston Road\n",
      "Cypress North Houston Rd => Cypress North Houston Road\n",
      "Rogerdale Road\n",
      "Rogerdale Rd => Rogerdale Road\n",
      "Hwy 6 South\n",
      "Hwy 6 S. => Hwy 6 South\n",
      "FM 1485 => FM 1485\n",
      "Palomar Valley Drive\n",
      "Palomar Valley Dr. => Palomar Valley Drive\n",
      "Bailey Street\n",
      "Bailey => Bailey Street\n",
      "Fondren Road # 7A => Fondren Road # 7A\n",
      "Farm to Market 1093 => Farm to Market 1093\n",
      "F.M. 1093 => F.M. 1093\n",
      "Durham Drive\n",
      "Durham => Durham Drive\n",
      "FM 1464 => FM 1464\n",
      "10039 Bissonnet St., => 10039 Bissonnet St.,\n",
      "FM 362 => FM 362\n",
      "Farm To Market Rd 529 => Farm To Market Rd 529\n",
      "Dallas St #A => Dallas St #A\n",
      "Richmond Ave, Ste B => Richmond Ave, Ste B\n",
      "North Sam Houston Pkwy East\n",
      "North Sam Houston Pkwy E => North Sam Houston Pkwy East\n",
      "FM 646 Rd East\n",
      "FM 646 Rd E => FM 646 Rd East\n",
      "Avenue East\n",
      "Avenue E => Avenue East\n",
      "San Felipe Road, suite F => San Felipe Road, suite F\n",
      "Tuam Street\n",
      "Tuam St => Tuam Street\n",
      "Canal Street\n",
      "Canal St => Canal Street\n",
      "Post Oak Boulevard\n",
      "Post Oak Blvd => Post Oak Boulevard\n",
      "Highway 6 South\n",
      "Highway 6 S => Highway 6 South\n",
      "Larchmont Road\n",
      "Larchmont => Larchmont Road\n",
      "US 90 => US 90\n",
      "FM 1640 => FM 1640\n",
      "Gulfcrest Street\n",
      "Gulfcrest => Gulfcrest Street\n",
      "I-45 => I-45\n",
      "Welford Drive\n",
      "Welford => Welford Drive\n",
      "E Parkwood Avenue\n",
      "E Parkwood Ave => E Parkwood Avenue\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- audit the OSMFILE and use the variable 'mapping' which reflects the changes needed \n",
    "    Note: not a generalized solution\n",
    "- update_name: actually fixes the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "\"\"\"\n",
    "\n",
    "OSMFILE = \"interpreter.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Circle\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Plaza\", \"Speedway\", \"Staffordshire\", \"Way\", \"Park\", \n",
    "            \"Freeway\", \"Loop\", \"130\", \"Block\", \"Walk\", \"North\", \"East\", \"South\", \"West\", \"59\", \"I-10\",\n",
    "           \"1960\", \"6\", \"Real\", \"Highway\", \"Trace\"]\n",
    "\n",
    "nums = [] #for use if we wanted to add street names that end with numbers to our expected list\n",
    "#for i in range(200): \n",
    "#    nums.append(str(i))\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\", \n",
    "            \"Stree\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\", \n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Maroneal\": \"Maroneal Street\",\n",
    "            \"Montrose\": \"Montrose Boulevard\", \n",
    "            \"Plaze\": \"Plaza\",\n",
    "            \"Graustark\": \"Graustark Street\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Bouldevard\", \n",
    "            \"Ln\": \"Lane\", \n",
    "            \"Ln.\": \"Lane\", \n",
    "            \"Pkwy\": \"Parkway\", \n",
    "            \"Dr\": \"Drive\", \n",
    "            \"Dr.\": \"Drive\", \n",
    "            \"Ct\": \"Court\", \n",
    "            \"Sq\": \"Square\", \n",
    "            \"Sq.\": \"Square\",\n",
    "            \"Lake\": \"Lane\",\n",
    "            \"Bailey\": \"Bailey Street\", \n",
    "            \"Oaks\": \"Oaks Block\",\n",
    "            \"Isle\": \"Isle Lane\", \n",
    "            \"Texas\": \"\", \n",
    "            \"Houston\": \"\",\n",
    "            \"Mews\": \"Mews Plantation\",\n",
    "            \"Cypress\": \"Cypress Road\",\n",
    "            \"N\": \"North\", \n",
    "           \"N.\": \"North\", \n",
    "           \"E\": \"East\", \n",
    "           \"E.\": \"East\", \n",
    "           \"S\": \"South\",\n",
    "           \"S.\": \"South\",\n",
    "           \"W\": \"West\",\n",
    "           \"W.\": \"West\",\n",
    "            \"Ste\": \"Suite\", \n",
    "            \"Ste.\": \"Suite\", \n",
    "           \"Driscoll\": \"Driscoll Street\",\n",
    "           \"Gulfcrest\": \"Gulfcrest Street\",\n",
    "           \"Larchmont\": \"Larchmont Road\", \n",
    "           \"Durham\": \"Durham Drive\", \n",
    "           \"Welford\": \"Welford Drive\"       \n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "unmapped = set()\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    street_type = street_type_re.search(name).group()\n",
    "    if street_type not in expected: \n",
    "        if street_type in mapping:\n",
    "            name = (name[:-len(street_type)] + mapping[street_type])\n",
    "            print name \n",
    "        else: \n",
    "            #print \"name not in mapping:\", street_type            \n",
    "            unmapped.add(name)\n",
    "            #just in case we want to take a look and make sure nothing crazy is in the unmapped set        \n",
    "    return name\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    pprint(dict(st_types))\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "            if name == \"West Lexington St.\":\n",
    "                assert better_name == \"West Lexington Street\"\n",
    "            if name == \"Baldwin Rd.\":\n",
    "                assert better_name == \"Baldwin Road\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load 'schema.py'\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering relevant data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code finished running\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\"\"\"\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "\n",
    "OSM_PATH = \"interpreter.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  \n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for item in element.attrib:\n",
    "            if item in NODE_FIELDS: \n",
    "                node_attribs[item] = element.attrib[item]\n",
    "        for child in element: \n",
    "            nodes = {}\n",
    "            k_problems = PROBLEMCHARS.search(child.attrib['k'])\n",
    "            k_semi_colon = LOWER_COLON.search(child.attrib['k'])\n",
    "            if k_problems:\n",
    "                pass \n",
    "            elif k_semi_colon:\n",
    "                m = k_semi_colon.group()\n",
    "                k_value_split = m.split(\":\")\n",
    "                if len(k_value_split) > 1:\n",
    "                    nodes[\"id\"]= element.attrib[\"id\"]\n",
    "                    nodes[\"key\"] = \"\".join(k_value_split[1:]) \n",
    "                    nodes[\"value\"] = child.attrib[\"v\"]\n",
    "                    nodes[\"type\"] = k_value_split[0]\n",
    "                    tags.append(nodes)\n",
    "            else: \n",
    "                nodes[\"id\"] = element.attrib[\"id\"]\n",
    "                nodes[\"key\"] = child.attrib[\"k\"]\n",
    "                nodes[\"value\"] = child.attrib[\"v\"]\n",
    "                nodes[\"type\"] = \"regular\"\n",
    "                tags.append(nodes)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for item in element.attrib:\n",
    "            if item in WAY_FIELDS:\n",
    "                way_attribs[item] = element.attrib[item]\n",
    "        pos = 0 \n",
    "        for child in element: \n",
    "            way_n = {} \n",
    "            way_t = {} \n",
    "            \n",
    "            if child.tag == \"nd\": \n",
    "                problems = PROBLEMCHARS.search(child.attrib[\"ref\"]) \n",
    "                if problems: \n",
    "                    pass \n",
    "                else: \n",
    "                    way_n[\"id\"] = element.attrib[\"id\"]\n",
    "                    way_n[\"node_id\"] = child.attrib[\"ref\"]\n",
    "                    way_n[\"position\"] = pos\n",
    "                    way_nodes.append(way_n)\n",
    "                    pos += 1\n",
    "                \n",
    "            if child.tag == \"tag\":\n",
    "                problems = PROBLEMCHARS.search(child.attrib[\"k\"]) \n",
    "                colattribs = LOWER_COLON.search(child.attrib[\"k\"])\n",
    "                \n",
    "                if problems:\n",
    "                    pass \n",
    "                elif colattribs: \n",
    "                    m = colattribs.group()\n",
    "                    splits = m.split(\":\")\n",
    "                    if len(splits) >1: \n",
    "                        way_t[\"id\"] = element.attrib[\"id\"]\n",
    "                        way_t[\"key\"] = \"\".join(splits[1:])\n",
    "                        way_t[\"value\"] = child.attrib[\"v\"]\n",
    "                        way_t[\"type\"] = splits[0]\n",
    "                        tags.append(way_t)\n",
    "                else: \n",
    "                    way_t[\"id\"] = element.attrib[\"id\"]\n",
    "                    way_t[\"key\"] = child.attrib[\"k\"]\n",
    "                    way_t[\"value\"] = child.attrib[\"v\"]\n",
    "                    way_t[\"type\"] = \"regular\"\n",
    "                    tags.append(way_t)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_map(OSM_PATH, validate=True)\n",
    "\n",
    "print \"Code finished running\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code finished\n"
     ]
    }
   ],
   "source": [
    "#$ sqlite3 create database;\n",
    "#connect to database - already created\n",
    "sqlite_file = 'interpreter.db'\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "conn.commit()\n",
    "cur.execute('''DROP TABLE IF EXISTS nodetags''')\n",
    "conn.commit()\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "conn.commit()\n",
    "cur.execute('''DROP TABLE IF EXISTS waytags''')\n",
    "conn.commit()\n",
    "cur.execute('''DROP TABLE IF EXISTS waynodes''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('''\n",
    "create table nodes \n",
    "(\n",
    "    nodeid integer primary key not null, \n",
    "    lat real, \n",
    "    lon real, \n",
    "    user text, \n",
    "    uid integer,\n",
    "    version integer,\n",
    "    changeset integer,\n",
    "    timestamp text  \n",
    ")''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('''\n",
    "create table nodetags\n",
    "(\n",
    "    id integer,\n",
    "    key text, \n",
    "    value text, \n",
    "    type text, \n",
    "    foreign key (id) references nodes (nodeid)\n",
    "\n",
    ")''')\n",
    "conn.commit()\n",
    "            \n",
    "#id above is the node id and is also the primary key for the nodes table \n",
    "cur.execute('''\n",
    "create table ways\n",
    "(\n",
    "    wayid integer primary key not null, \n",
    "    user text, \n",
    "    uid integer, \n",
    "    version text, \n",
    "    changeset integer,\n",
    "    timestamp text\n",
    ")''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('''\n",
    "\n",
    "create table waynodes\n",
    "(\n",
    "    wayid integer not null, \n",
    "    node_id integer not null, \n",
    "    position integer not null, \n",
    "    foreign key (wayid) references ways (wayid)\n",
    "    foreign key (node_id) references nodes (nodeid)\n",
    "\n",
    ")''')\n",
    "conn.commit()             \n",
    "#id above is a way id and different from a node id\n",
    " \n",
    "cur.execute('''\n",
    "    \n",
    "create table waytags \n",
    "(\n",
    "    wayid integer not null, \n",
    "    key text not null, \n",
    "    value text not null, \n",
    "    type text not null, \n",
    "    foreign key (wayid) references ways (wayid)\n",
    "\n",
    ")''')\n",
    "conn.commit()\n",
    "\n",
    "print \"code finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data into the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code finished\n"
     ]
    }
   ],
   "source": [
    "# Read in the csv file as a dictionary, format the data as a list of tuples:\n",
    "\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'],i['lon'], i['user'].decode(\"utf-8\"), i['uid'], i['version'],i['changeset'], i['timestamp']) for i in dr]\n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(nodeid, lat, lon , user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    " \n",
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "cur.executemany(\"INSERT INTO nodetags(id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'].decode(\"utf-8\"),i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "cur.executemany(\"INSERT INTO ways(wayid, user, uid , version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['node_id'],i['position']) for i in dr]\n",
    "cur.executemany(\"INSERT INTO waynodes(wayid, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "cur.executemany(\"INSERT INTO waytags(wayid, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "print \"Code finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:  66749940\n",
      "Nodes CSV:  23374752\n",
      "Nodes Tags CSV:  564723\n",
      "Ways CSV:  2452684\n",
      "Ways Tags CSV:  6043017\n",
      "Ways Nodes CSV:  8296465\n",
      "Database:  35467264\n"
     ]
    }
   ],
   "source": [
    "# File size \n",
    "import os\n",
    "print \"Original Data: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/interpreter.osm')\n",
    "print \"Nodes CSV: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/nodes.csv')\n",
    "print \"Nodes Tags CSV: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/nodes_tags.csv')\n",
    "print \"Ways CSV: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/ways.csv')\n",
    "print \"Ways Tags CSV: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/ways_tags.csv')\n",
    "print \"Ways Nodes CSV: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/ways_nodes.csv')\n",
    "print \"Database: \", os.path.getsize('/Users/irasema/Desktop/DataScience/Udacity/Data Analyst/Project 2/interpreter.db')\n",
    "\n",
    "#Resource:\n",
    "#https://stackoverflow.com/questions/6591931/getting-file-size-in-python\n",
    "#https://docs.python.org/3/library/os.path.html#os.path.getsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are all data coordinates within the limits of the original query? Is anything out of place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0          1         2          3\n",
      "0  30.1831  29.463502 -94.82301 -96.100149\n"
     ]
    }
   ],
   "source": [
    "query = ''' select max(lat), min(lat), max(lon), min(lon) from nodes '''\n",
    "db = sqlite3.connect(\"interpreter.db\")\n",
    "cursor = db.cursor()\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates seem to all fall within the Houston metropolitan area. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many Nodes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0  278542\n"
     ]
    }
   ],
   "source": [
    "cursor = db.cursor()\n",
    "query = \"select count(*) from nodes\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  41283\n"
     ]
    }
   ],
   "source": [
    "query = \"Select count(*) from ways\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  15045\n"
     ]
    }
   ],
   "source": [
    "query = \"Select count(*) from nodetags\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Way tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0  172130\n"
     ]
    }
   ],
   "source": [
    "query = \"Select count(*) from waytags\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most common node tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0                  1     2\n",
      "0     highway     turning_circle  2313\n",
      "1       power              tower  1379\n",
      "2       power               pole   932\n",
      "3     highway    traffic_signals   751\n",
      "4     highway           crossing   358\n",
      "5     highway       turning_loop   331\n",
      "6     railway     level_crossing   321\n",
      "7    state_id                 48   273\n",
      "8   county_id                201   225\n",
      "9       state                 TX   219\n",
      "10    natural               tree   205\n",
      "11    amenity   place_of_worship   193\n",
      "12   religion          christian   188\n",
      "13       city            Houston   177\n",
      "14    barrier               gate   163\n",
      "15     noexit                yes   135\n",
      "16   building              house   127\n",
      "17    highway  motorway_junction   113\n",
      "18    created         12/08/2003   112\n",
      "19   crossing              zebra    91\n"
     ]
    }
   ],
   "source": [
    "query = ''' select key, value, count(*) as count from nodetags \n",
    "group by key, value order by count desc limit 20 \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most common way tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0                                                  1      2\n",
      "0          cfcc                                                A41  11581\n",
      "1      reviewed                                                 no  10782\n",
      "2        county                                         Harris, TX  10533\n",
      "3       highway                                        residential   9567\n",
      "4       highway                                            service   8550\n",
      "5      building                                                yes   7425\n",
      "6        oneway                                                yes   4936\n",
      "7     separated                                                 no   4376\n",
      "8        source                     tiger_import_dch_v0.6_20070830   3779\n",
      "9      building                                              house   2857\n",
      "10      service                                           driveway   2425\n",
      "11    name_type                                                 Dr   2395\n",
      "12      highway                                          secondary   2045\n",
      "13      highway                                            footway   1679\n",
      "14    name_type                                                 St   1586\n",
      "15      surface                                    concrete:plates   1489\n",
      "16  upload_uuid  bulk_upload.pl-2a56bf02-3df4-478d-b466-4d8101e...   1380\n",
      "17    name_type                                                 Rd   1349\n",
      "18       county                                      Fort Bend, TX   1343\n",
      "19      service                                      parking_aisle   1243\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Select key, value, count(*) as count from waytags group by key, value \n",
    "order by count desc limit 20 \n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about across way and node tags? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0                                                  1      2\n",
      "0          cfcc                                                A41  11581\n",
      "1      reviewed                                                 no  10840\n",
      "2        county                                         Harris, TX  10533\n",
      "3       highway                                        residential   9567\n",
      "4       highway                                            service   8550\n",
      "5      building                                                yes   7457\n",
      "6        oneway                                                yes   4936\n",
      "7     separated                                                 no   4376\n",
      "8        source                     tiger_import_dch_v0.6_20070830   3779\n",
      "9      building                                              house   2984\n",
      "10      service                                           driveway   2425\n",
      "11    name_type                                                 Dr   2395\n",
      "12      highway                                     turning_circle   2313\n",
      "13      highway                                          secondary   2045\n",
      "14      highway                                            footway   1679\n",
      "15    name_type                                                 St   1586\n",
      "16      surface                                    concrete:plates   1491\n",
      "17  upload_uuid  bulk_upload.pl-2a56bf02-3df4-478d-b466-4d8101e...   1380\n",
      "18        power                                              tower   1379\n",
      "19    name_type                                                 Rd   1349\n",
      "20       county                                      Fort Bend, TX   1343\n",
      "21      service                                      parking_aisle   1243\n",
      "22       source                                               Bing   1021\n",
      "23        power                                               pole    932\n",
      "24       source                     tiger_import_dch_v0.6_20070829    866\n",
      "25    name_type                                                 Ln    833\n",
      "26      highway                                    traffic_signals    751\n",
      "27       bridge                                                yes    642\n",
      "28    name_type                                                 Ct    630\n",
      "29      highway                                           tertiary    610\n",
      "30        state                                                 TX    609\n",
      "31        lanes                                             left||    599\n",
      "32        layer                                                  1    588\n",
      "33      railway                                               rail    571\n",
      "34      surface                                            asphalt    561\n",
      "35       access                                            private    555\n",
      "36        lanes                                                  2    554\n",
      "37        gauge                                               1435    545\n",
      "38      surface                                           concrete    506\n",
      "39         cfcc                                                A45    502\n"
     ]
    }
   ],
   "source": [
    "query = ''' select key, value, count(*) as count\n",
    "from (select * from waytags union all select * from nodetags) as subq\n",
    "group by key, value order by count desc limit 40 \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are there so many zebra crossing tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0             1      2        3\n",
      "0    152566394      crossing  zebra  regular\n",
      "1    152595847      crossing  zebra  regular\n",
      "2   2595305241      crossing  zebra  regular\n",
      "3   2920452327      crossing  zebra  regular\n",
      "4   2982750738      crossing  zebra  regular\n",
      "5   2982750748      crossing  zebra  regular\n",
      "6   3121179043      crossing  zebra  regular\n",
      "7   3132361363      crossing  zebra  regular\n",
      "8   3132361384      crossing  zebra  regular\n",
      "9   3220290864      crossing  zebra  regular\n",
      "10  3242607179      crossing  zebra  regular\n",
      "11  3253105978  crossing_ref  zebra  regular\n",
      "12  3568506288      crossing  zebra  regular\n",
      "13  3568506378      crossing  zebra  regular\n",
      "14  3580613997      crossing  zebra  regular\n",
      "15  3662128893      crossing  zebra  regular\n",
      "16  3723389250      crossing  zebra  regular\n",
      "17  3872980273      crossing  zebra  regular\n",
      "18  4020665615      crossing  zebra  regular\n",
      "19  4247739958      crossing  zebra  regular\n",
      "20  4247757690      crossing  zebra  regular\n",
      "21  4247757710      crossing  zebra  regular\n",
      "22  4247757720      crossing  zebra  regular\n",
      "23  4247757770      crossing  zebra  regular\n",
      "24  4247757848      crossing  zebra  regular\n",
      "25  4249212378      crossing  zebra  regular\n",
      "26  4249212968      crossing  zebra  regular\n",
      "27  4249293031      crossing  zebra  regular\n",
      "28  4249293192      crossing  zebra  regular\n",
      "29  4249293602      crossing  zebra  regular\n",
      "..         ...           ...    ...      ...\n",
      "63  4289546642      crossing  zebra  regular\n",
      "64  4297141820      crossing  zebra  regular\n",
      "65  4297141963      crossing  zebra  regular\n",
      "66  4297226014      crossing  zebra  regular\n",
      "67  4297378805      crossing  zebra  regular\n",
      "68  4297378825      crossing  zebra  regular\n",
      "69  4303258334      crossing  zebra  regular\n",
      "70  4308351769      crossing  zebra  regular\n",
      "71  4308352189      crossing  zebra  regular\n",
      "72  4308352361      crossing  zebra  regular\n",
      "73  4322352189      crossing  zebra  regular\n",
      "74  4322377710      crossing  zebra  regular\n",
      "75  4324511446      crossing  zebra  regular\n",
      "76  4324511456      crossing  zebra  regular\n",
      "77  4324511466      crossing  zebra  regular\n",
      "78  4324552095      crossing  zebra  regular\n",
      "79  4324603848      crossing  zebra  regular\n",
      "80  4326374133      crossing  zebra  regular\n",
      "81  4326374153      crossing  zebra  regular\n",
      "82  4326374183      crossing  zebra  regular\n",
      "83  4326374803      crossing  zebra  regular\n",
      "84  4373155282      crossing  zebra  regular\n",
      "85  4491234212  crossing_ref  zebra  regular\n",
      "86  4539662662      crossing  zebra  regular\n",
      "87  4641442682      crossing  zebra  regular\n",
      "88  4641443402      crossing  zebra  regular\n",
      "89  5178608307      crossing  zebra  regular\n",
      "90  5221898837      crossing  zebra  regular\n",
      "91  5221950825      crossing  zebra  regular\n",
      "92  5221955936      crossing  zebra  regular\n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"Select id, key, value, type from nodetags where value = 'zebra'\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0          1           2             3      4        5          6  \\\n",
      "0   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "1   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "2   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "3   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "4   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "5   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "6   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "7   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "8   30.048567 -95.151942  3568506288      crossing  zebra  regular   15443194   \n",
      "9   30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "10  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "11  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "12  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "13  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "14  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "15  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "16  30.059441 -95.244726  4274821477      crossing  zebra  regular   21863953   \n",
      "17  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "18  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "19  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "20  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "21  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "22  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "23  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "24  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "25  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "26  29.753073 -95.364155  4326374183      crossing  zebra  regular   44530794   \n",
      "27  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "28  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "29  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "30  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "31  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "32  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "33  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "34  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "35  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "36  29.757732 -95.377776  4324552095      crossing  zebra  regular  103371609   \n",
      "37  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "38  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "39  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "40  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "41  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "42  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "43  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "44  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "45  30.049240 -95.199779  4297141820      crossing  zebra  regular  177256230   \n",
      "46  29.719185 -95.339054  3253105978  crossing_ref  zebra  regular  363824003   \n",
      "47  29.719185 -95.339054  3253105978  crossing_ref  zebra  regular  363824003   \n",
      "48  29.719185 -95.339054  3253105978  crossing_ref  zebra  regular  363824003   \n",
      "49  29.719185 -95.339054  3253105978  crossing_ref  zebra  regular  363824003   \n",
      "50  29.676471 -95.482421  3872980273      crossing  zebra  regular  383999052   \n",
      "51  29.676471 -95.482421  3872980273      crossing  zebra  regular  383999052   \n",
      "52  30.045595 -95.181159  4253329963      crossing  zebra  regular  426008361   \n",
      "53  30.047656 -95.185581   152595847      crossing  zebra  regular  430859784   \n",
      "54  30.047656 -95.185581   152595847      crossing  zebra  regular  430859784   \n",
      "55  30.047656 -95.185581   152595847      crossing  zebra  regular  430859784   \n",
      "56  29.550080 -95.092797  4641443402      crossing  zebra  regular  469885886   \n",
      "57  29.550080 -95.092797  4641443402      crossing  zebra  regular  469885886   \n",
      "58  29.550080 -95.092797  4641443402      crossing  zebra  regular  469885886   \n",
      "\n",
      "                        7                      8        9  \n",
      "0                    cfcc                    A41    tiger  \n",
      "1                  county             Harris, TX    tiger  \n",
      "2                 highway            residential  regular  \n",
      "3                    name     Seven Maples Drive  regular  \n",
      "4               name_base           Seven Maples    tiger  \n",
      "5               name_type                     Dr    tiger  \n",
      "6                reviewed                     no    tiger  \n",
      "7                zip_left                  77345    tiger  \n",
      "8               zip_right                  77345    tiger  \n",
      "9                    cfcc                    A41    tiger  \n",
      "10                 county         Montgomery, TX    tiger  \n",
      "11                highway            residential  regular  \n",
      "12                   name  Northpark Plaza Drive  regular  \n",
      "13              name_base             North Park    tiger  \n",
      "14              name_type                    Plz    tiger  \n",
      "15                 oneway                    yes  regular  \n",
      "16               reviewed                     no    tiger  \n",
      "17                bicycle             designated  regular  \n",
      "18                   cfcc                    A41    tiger  \n",
      "19                 county             Harris, TX    tiger  \n",
      "20                highway              secondary  regular  \n",
      "21                   name        Caroline Street  regular  \n",
      "22              name_base               Caroline    tiger  \n",
      "23              name_type                     St    tiger  \n",
      "24                 oneway                    yes  regular  \n",
      "25               zip_left                  77004    tiger  \n",
      "26              zip_right                  77004    tiger  \n",
      "27                   cfcc                    A41    tiger  \n",
      "28                 county             Harris, TX    tiger  \n",
      "29                highway              secondary  regular  \n",
      "30                   name     West Dallas Street  regular  \n",
      "31              name_base                 Dallas    tiger  \n",
      "32  name_direction_prefix                      W    tiger  \n",
      "33              name_type                    Ave    tiger  \n",
      "34               old_name      San Felipe Street  regular  \n",
      "35               zip_left                  77019    tiger  \n",
      "36              zip_right                  77019    tiger  \n",
      "37                   cfcc                    A45    tiger  \n",
      "38                 county             Harris, TX    tiger  \n",
      "39                highway            residential  regular  \n",
      "40                   name     Valley Manor Drive  regular  \n",
      "41              name_base           Valley Manor    tiger  \n",
      "42              name_type                     Dr    tiger  \n",
      "43               reviewed                     no    tiger  \n",
      "44               zip_left                  77339    tiger  \n",
      "45              zip_right                  77339    tiger  \n",
      "46                bicycle                    yes  regular  \n",
      "47                   foot                    yes  regular  \n",
      "48                highway                footway  regular  \n",
      "49                surface               concrete  regular  \n",
      "50                highway                footway  regular  \n",
      "51                surface        concrete:plates  regular  \n",
      "52                highway                footway  regular  \n",
      "53               crossing                  zebra  regular  \n",
      "54                footway               crossing  regular  \n",
      "55                highway                footway  regular  \n",
      "56               crossing                  zebra  regular  \n",
      "57                footway               crossing  regular  \n",
      "58                highway                footway  regular  \n"
     ]
    }
   ],
   "source": [
    "#Combining tables to get additional information on Zebra tags\n",
    "#Filters for node tags involving the 'zebra' value\n",
    "query = '''Select nodes.lat, nodes.lon, nodeid, nodetags.key, nodetags.value, nodetags.type, \n",
    "waytags.wayid, waytags.key, waytags.value, waytags.type\n",
    "from nodes, nodetags, ways, waytags, waynodes where nodes.nodeid = nodetags.id \n",
    "and waynodes.wayid = waytags.wayid and ways.wayid = waynodes.wayid \n",
    "and waynodes.node_id = nodes.nodeid \n",
    "and nodetags.value = 'zebra' \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further exploration, (looking at key/value pairs, googling the lat/lon, and googling the phrase 'zebra crossings osm') it seems the zebra crossing is a type of crosswalk (nonspecific to zebras or painted as zebras for the Houston Zoo). \n",
    "\n",
    "This may be an example of not when understanding the data leads to findings that may seem off but after some digging, actually make sense. I figured though the result was not noteable and could wholely be taken out of the report, the investigative procedure is helpful to demonstrate. \n",
    "\n",
    "https://wiki.openstreetmap.org/wiki/Approved_features/Road_crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1\n",
      "0  77096  51\n",
      "1  77339  18\n",
      "2  77401  18\n",
      "3  77002   8\n",
      "4  77076   7\n",
      "5  77586   7\n",
      "6  77006   6\n",
      "7  77098   5\n",
      "8  77027   4\n",
      "9  77085   4\n"
     ]
    }
   ],
   "source": [
    "query = ''' select value, count(*) as count from nodetags \n",
    "where key = 'postcode' \n",
    "group by value \n",
    "order by count desc\n",
    "limit 10\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Houston Metropolitan area is fairly large and covers a range of postcodes. After some searching, I determined that most of the postcodes above actually fall within the area. However, the postcode 88581 actually belongs to El Paso, Texas.\n",
    "\n",
    "Resources: \n",
    "https://data.mongabay.com/igapo/zip_codes/metropolitan-areas/metro-alpha/Houston%20(TX)1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0        1\n",
      "0           brianboru     9065\n",
      "1           davidearl     3582\n",
      "2     woodpeck_repair   145231\n",
      "3           andrewpmk     1679\n",
      "4     woodpeck_fixbot   147510\n",
      "5             scottyc   496606\n",
      "6            afdreher  1110270\n",
      "7              clay_c   119881\n",
      "8       RoadGeek_MD99   475877\n",
      "9             Memoire  2176227\n",
      "10        NayanataraM  2053369\n",
      "11             choess   396743\n",
      "12           Sundance   239998\n",
      "13           karitotp  2748195\n",
      "14           KristenK  1494110\n",
      "15            cammace  3119079\n",
      "16          Bootprint    76077\n",
      "17          Bellhalla   219655\n",
      "18        maxerickson   360392\n",
      "19          EiderDuck  1924872\n",
      "20            skquinn   243003\n",
      "21            ridixcr  2508151\n",
      "22             chewey  1208453\n",
      "23              MikeN   135163\n",
      "24           Iowa Kid   703517\n",
      "25            wikewag  5319602\n",
      "26                NE2   207745\n",
      "27            ELadner    22925\n",
      "28        gridlockjoe    70659\n",
      "29            dufekin    30521\n",
      "...               ...      ...\n",
      "1363            pfgis  2034630\n",
      "1364         norcross  6319165\n",
      "1365       jmoore2422  5682658\n",
      "1366       Zac Cooper  3451302\n",
      "1367          tdiesel   325973\n",
      "1368           verdra  7112449\n",
      "1369           ersatz  5388003\n",
      "1370  ashleyannmathew  4994101\n",
      "1371        geohacker   146675\n",
      "1372  poornibadrinath  1597155\n",
      "1373    Anthonyfish46  3771923\n",
      "1374          rowers2  2445224\n",
      "1375    istvan_bardos  2740857\n",
      "1376           Asotia  5008884\n",
      "1377            kabz1  5183011\n",
      "1378         mueschel   616774\n",
      "1379    Will Holdrich  6067670\n",
      "1380          SAubrey  7546400\n",
      "1381            fuchy  5464785\n",
      "1382       KevinMcGee  4870716\n",
      "1383          cebaros  3346056\n",
      "1384     Justin Toman  6584740\n",
      "1385         carciofo  2533093\n",
      "1386          openb0x  6966793\n",
      "1387        dpaschich   621202\n",
      "1388   Nakaner-repair  2149259\n",
      "1389         DRAGOSTN  7655599\n",
      "1390  NickValdez80085  7775466\n",
      "1391     MannyTheGeek  7929144\n",
      "1392     GarrettW2000  8050314\n",
      "\n",
      "[1393 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# This query combines the nodes and ways table to find all users who have contributed to either\n",
    "query = ''' select distinct(subq.user), uid\n",
    "from (select uid, user from nodes union all select uid, user from ways) subq\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 contributors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                1      2\n",
      "0  1110270         afdreher  50264\n",
      "1   147510  woodpeck_fixbot  35051\n",
      "2   496606          scottyc  19328\n",
      "3  3119079          cammace  19259\n",
      "4   119881           clay_c  16125\n",
      "5     9065        brianboru  11224\n",
      "6   243003          skquinn   8680\n",
      "7   475877    RoadGeek_MD99   7622\n",
      "8   672878         TexasNHD   7005\n",
      "9  2176227          Memoire   6540\n"
     ]
    }
   ],
   "source": [
    "# top 10 contributing users across the nodes and ways tables \n",
    "query = ''' select uid, subq.user, count(*) as count\n",
    "from \n",
    "(select uid, user from nodes union all select uid, user from ways) as subq\n",
    "group by subq.user\n",
    "order by count desc\n",
    "limit 10\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users with 1 post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  265\n"
     ]
    }
   ],
   "source": [
    "query = ''' \n",
    "select count (*) from \n",
    "(select uid, user, count(*) as counts\n",
    "from (select uid, user from nodes union all select uid, user from ways) as subq\n",
    "group by subq.user\n",
    "having counts = 1\n",
    "order by counts desc ) as substuff \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            0                     1   2\n",
      "0                                      Subway              sandwich  11\n",
      "1                                     Wendy's                burger   7\n",
      "2                             Jack in the Box                burger   4\n",
      "3                                  McDonald's                burger   4\n",
      "4                                 Chick-fil-A               chicken   3\n",
      "5                           Schlotzsky's Deli              sandwich   3\n",
      "6                                 Whataburger                burger   3\n",
      "7                                 Burger King                burger   2\n",
      "8                                 Jamba Juice                drinks   2\n",
      "9                                         KFC               chicken   2\n",
      "10                            Little Caesar's                 pizza   2\n",
      "11                              Panda Express               chinese   2\n",
      "12                                   Popeye's               chicken   2\n",
      "13                                      Sonic                burger   2\n",
      "14                                   3 Chiles               mexican   1\n",
      "15                              Alamo Tamales               mexican   1\n",
      "16                              Alli Pizzeria                 pizza   1\n",
      "17          Bahama Buck's Original Shaved Ice             ice_cream   1\n",
      "18                                Becks Prime                burger   1\n",
      "19                         Bombay Sweets Inc.                indian   1\n",
      "20                              Boston Market              american   1\n",
      "21                                   BreWingz                 wings   1\n",
      "22  California Pizza Kitchen at Huges Landing                 pizza   1\n",
      "23                             Casa de Bravos               mexican   1\n",
      "24                                    Chili's              american   1\n",
      "25                                   Chipotle               mexican   1\n",
      "26                           Church's Chicken               chicken   1\n",
      "27                                     Cici's                 pizza   1\n",
      "28             Dimassi's Mediterranean Buffet  mediterranean;buffet   1\n",
      "29                             Domino's Pizza                 pizza   1\n",
      "..                                        ...                   ...  ..\n",
      "46                           Luigi's Pizzeria                 pizza   1\n",
      "47                        Marble Slab Cremery             ice_cream   1\n",
      "48                         Mediterranean Chef                 greek   1\n",
      "49                        Mia Bella Trattoria               italian   1\n",
      "50                              Midnite Slice                 pizza   1\n",
      "51                               Mogul Indian                indian   1\n",
      "52                                  Mom Alone               mexican   1\n",
      "53                        Old Hickory Inn BBQ              barbecue   1\n",
      "54                               Patronella's               italian   1\n",
      "55                             Petrol Station          local;burger   1\n",
      "56                                  Pizza Hut                 pizza   1\n",
      "57                     Popeye's Fried Chicken               chicken   1\n",
      "58                     Potbelly Sandwich Shop              sandwich   1\n",
      "59                                     Puerto               mexican   1\n",
      "60                          Relish Fine Foods              sandwich   1\n",
      "61                                 Simply Pho            vietnamese   1\n",
      "62                                Smashburger                burger   1\n",
      "63                Southwell's Hamburger Grill                burger   1\n",
      "64                                 Star Pizza                 pizza   1\n",
      "65                                 Sushi Raku                 sushi   1\n",
      "66                                  Taco Bell               mexican   1\n",
      "67                                Taco Cabana               mexican   1\n",
      "68                                 Thai Spice                  thai   1\n",
      "69                      Tony's New York Pizza                 pizza   1\n",
      "70                               Tutti Frutti             ice_cream   1\n",
      "71                                Villa Capri               italian   1\n",
      "72                                  Wing-Stop                 wings   1\n",
      "73                                      Xochi        Oaxaca;mexican   1\n",
      "74                                 Yokohamaya              japanese   1\n",
      "75                           green seed vegan                 vegan   1\n",
      "\n",
      "[76 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Note, this query only draws from nodetags (not waytags - to be addressed later) \n",
    "query = ''' select names.name, value, count (*) as count \n",
    "from nodetags, \n",
    "(SELECT distinct(id) as restid FROM nodetags WHERE value= 'restaurant' or value= 'fast_food') \n",
    "as rest, \n",
    "(select value as name, id as nameid from nodetags where key = 'name') as names \n",
    "\n",
    "where nodetags.id = rest.restid \n",
    "and nodetags.id = names.nameid \n",
    "and nodetags.key = 'cuisine' \n",
    "\n",
    "group by name \n",
    "order by count desc \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most prevalent cuisines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0   1\n",
      "0                 burger  26\n",
      "1               sandwich  16\n",
      "2                  pizza  13\n",
      "3                mexican  12\n",
      "4                chicken   9\n",
      "5                italian   4\n",
      "6              ice_cream   3\n",
      "7               american   2\n",
      "8               barbecue   2\n",
      "9                chinese   2\n",
      "10                drinks   2\n",
      "11                indian   2\n",
      "12        latin_american   2\n",
      "13                 wings   2\n",
      "14        Oaxaca;mexican   1\n",
      "15                 asian   1\n",
      "16             breakfast   1\n",
      "17                 cajun   1\n",
      "18                 greek   1\n",
      "19              japanese   1\n",
      "20          local;burger   1\n",
      "21         mediterranean   1\n",
      "22  mediterranean;buffet   1\n",
      "23                   pie   1\n",
      "24                 sushi   1\n",
      "25                  thai   1\n",
      "26                 vegan   1\n",
      "27            vietnamese   1\n"
     ]
    }
   ],
   "source": [
    "# Overall, what cuisines are most prevalent? \n",
    "\n",
    "query = ''' select value, count (*) as count\n",
    "from nodetags, \n",
    "(SELECT distinct(id) as restid FROM nodetags WHERE value= 'restaurant' or value = 'fast_food') as rest, \n",
    "(select value as name, id as nameid from nodetags where key = 'name') as names \n",
    "\n",
    "where nodetags.id = rest.restid \n",
    "and nodetags.id = names.nameid \n",
    "and nodetags.key = 'cuisine' \n",
    "\n",
    "group by value \n",
    "order by count desc\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0                1   2\n",
      "0                    Whataburger           burger  13\n",
      "1                     McDonald's           burger   4\n",
      "2                    Burger King           burger   3\n",
      "3                    Chick-fil-A          chicken   3\n",
      "4                Jack in the Box           burger   2\n",
      "5                  Panda Express          chinese   2\n",
      "6                    Taco Cabana          mexican   2\n",
      "7                 Baskin-Robbins        ice_cream   1\n",
      "8                 Breakfast Klub  diner;breakfast   1\n",
      "9                      Carl's Jr           burger   1\n",
      "10                      Chipotle          mexican   1\n",
      "11                   Fudrucker's           burger   1\n",
      "12                Goodson's Cafe         american   1\n",
      "13          Hartz Chicken Buffet          chicken   1\n",
      "14               Jack In The Box           burger   1\n",
      "15                     Los Cucos          mexican   1\n",
      "16  Los Cucos Mexican Restaurant           texmex   1\n",
      "17                  Olive Garden          italian   1\n",
      "18              Sam's Deli Diner           burger   1\n",
      "19             Schlotzsky's Deli         sandwich   1\n",
      "20                         Sonic           burger   1\n",
      "21     Straight Off The Road BBQ         barbeque   1\n",
      "22                        Subway         sandwich   1\n",
      "23                 The Mason Jar         american   1\n",
      "24                       Wendy's           burger   1\n",
      "25                        Wendys           burger   1\n"
     ]
    }
   ],
   "source": [
    "# What are the most popular places and their corresponding cuisine? \n",
    "# Note: This query draws from waytags not nodetags \n",
    "\n",
    "query = ''' select names.name, value, count (*) as count \n",
    "from waytags, \n",
    "(SELECT distinct(wayid) as restid FROM waytags WHERE value= 'restaurant' or value= 'fast_food') \n",
    "as rest, \n",
    "(select value as name, wayid as nameid from waytags where key = 'name') as names \n",
    "\n",
    "where waytags.wayid = rest.restid \n",
    "and waytags.wayid = names.nameid \n",
    "and waytags.key = 'cuisine' \n",
    "\n",
    "group by name \n",
    "order by count desc \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast food information? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0                          1\n",
      "0          amenity                  fast_food\n",
      "1          cuisine                     burger\n",
      "2             name                Burger King\n",
      "3          amenity                  fast_food\n",
      "4          cuisine                    chicken\n",
      "5             name     Popeye's Fried Chicken\n",
      "6          website    http://www.popeyes.com/\n",
      "7          amenity                  fast_food\n",
      "8             name            Jack in the Box\n",
      "9             city                    Tomball\n",
      "10           state                         TX\n",
      "11         amenity                  fast_food\n",
      "12           is_in                Tomball, Tx\n",
      "13            name                  Pizza Hut\n",
      "14         amenity                  fast_food\n",
      "15         cuisine                     burger\n",
      "16        delivery                         no\n",
      "17   drive_through                        yes\n",
      "18            name                      Sonic\n",
      "19            city                     Spring\n",
      "20     housenumber                       2681\n",
      "21        postcode                      77386\n",
      "22          street               Rayford Road\n",
      "23         amenity                  fast_food\n",
      "24         cuisine                    mexican\n",
      "25            name                  Taco Bell\n",
      "26            city                   La Porte\n",
      "27     housenumber                       9101\n",
      "28        postcode                      77571\n",
      "29           state                         TX\n",
      "..             ...                        ...\n",
      "313           name                Chick-fil-A\n",
      "314        amenity                  fast_food\n",
      "315           name  Popeyes Louisiana Kitchen\n",
      "316        amenity                  fast_food\n",
      "317           name                     Subway\n",
      "318    housenumber                       7810\n",
      "319         street   FM 1960 Bypass West Road\n",
      "320        amenity                  fast_food\n",
      "321           name            Jack in the Box\n",
      "322        amenity                  fast_food\n",
      "323           name                   Potbelly\n",
      "324        amenity                  fast_food\n",
      "325           name               Cici's Pizza\n",
      "326        amenity                  fast_food\n",
      "327        cuisine                     burger\n",
      "328           name            Jack in the Box\n",
      "329        amenity                  fast_food\n",
      "330           name       Pupusería Las Brisas\n",
      "331        amenity                  fast_food\n",
      "332        cuisine                     burger\n",
      "333           name                 McDonald's\n",
      "334           city                    Houston\n",
      "335    housenumber                       6127\n",
      "336       postcode                      77057\n",
      "337          state                         TX\n",
      "338         street            Westheimer Road\n",
      "339        amenity                  fast_food\n",
      "340        cuisine                   sandwich\n",
      "341           name          Schlotzsky's Deli\n",
      "342          phone             (713) 974-2867\n",
      "\n",
      "[343 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# This query draws from the node_ids of fast_food restaurants and gives \n",
    "# the additional information that are stored in related nodetags\n",
    "query = ''' \n",
    "SELECT key, value from nodetags, \n",
    "(select distinct(id) from nodetags where value = 'fast_food') as fast \n",
    "where nodetags.id = fast.id \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common amenities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         0    1\n",
      "0         place_of_worship  193\n",
      "1                fast_food   89\n",
      "2                 fountain   89\n",
      "3               restaurant   81\n",
      "4                   school   57\n",
      "5                    bench   33\n",
      "6             fire_station   24\n",
      "7                     fuel   23\n",
      "8                     bank   20\n",
      "9                 pharmacy   20\n",
      "10                    cafe   19\n",
      "11                 toilets   12\n",
      "12                  police   11\n",
      "13          drinking_water    9\n",
      "14                     atm    8\n",
      "15                 dentist    8\n",
      "16                 parking    8\n",
      "17                     bar    7\n",
      "18                  clinic    6\n",
      "19                post_box    5\n",
      "20                     pub    5\n",
      "21            waste_basket    5\n",
      "22          bicycle_rental    4\n",
      "23                 doctors    4\n",
      "24                 library    4\n",
      "25  bicycle_repair_station    3\n",
      "26                car_wash    3\n",
      "27              grave_yard    3\n",
      "28             arts_centre    2\n",
      "29        charging_station    2\n",
      "30                hospital    2\n",
      "31             post_office    2\n",
      "32                 shelter    2\n",
      "33                    shop    2\n",
      "34                 theatre    2\n",
      "35                townhall    2\n",
      "36              veterinary    2\n",
      "37        bureau_de_change    1\n",
      "38              car_rental    1\n",
      "39                  casino    1\n",
      "40                  cinema    1\n",
      "41                    dojo    1\n",
      "42               ice_cream    1\n",
      "43             marketplace    1\n",
      "44               nightclub    1\n",
      "45            nursing_home    1\n",
      "46                  studio    1\n",
      "47                   tutor    1\n",
      "48              university    1\n"
     ]
    }
   ],
   "source": [
    "# Note this query only accounts for node tags \n",
    "query = ''' select value, count(*) as count from nodetags \n",
    "where key = 'amenity' \n",
    "group by value\n",
    "order by count desc\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    1\n",
      "0            parking  411\n",
      "1             school   94\n",
      "2          fast_food   45\n",
      "3               fuel   37\n",
      "4   place_of_worship   37\n",
      "5         restaurant   27\n",
      "6               bank   12\n",
      "7            shelter   11\n",
      "8           car_wash   10\n",
      "9           pharmacy   10\n",
      "10              cafe    7\n",
      "11          hospital    7\n",
      "12          fountain    6\n",
      "13        grave_yard    6\n",
      "14           toilets    6\n",
      "15               bar    4\n",
      "16      fire_station    4\n",
      "17           library    4\n",
      "18            cinema    3\n",
      "19   bicycle_parking    2\n",
      "20            clinic    2\n",
      "21  community_centre    2\n",
      "22         nightclub    2\n",
      "23       post_office    2\n",
      "24            prison    2\n",
      "25     swimming_pool    2\n",
      "26        university    2\n",
      "27       bus_station    1\n",
      "28        car_rental    1\n",
      "29           college    1\n",
      "30           embassy    1\n",
      "31     parking_space    1\n",
      "32   public_building    1\n",
      "33          shopping    1\n",
      "34          townhall    1\n",
      "35        veterinary    1\n"
     ]
    }
   ],
   "source": [
    "# Note this query only accounts for way tags \n",
    "query = ''' select value, count(*) as count from waytags \n",
    "where key = 'amenity' \n",
    "group by value\n",
    "order by count desc\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common cities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0               1    2\n",
      "0   city         Houston  177\n",
      "1   city        Bellaire   25\n",
      "2   city        Kingwood   19\n",
      "3   city        Seabrook    7\n",
      "4   city          Spring    7\n",
      "5   city   Missouri City    5\n",
      "6   city         Cypress    4\n",
      "7   city     Houston, TX    4\n",
      "8   city         Tomball    4\n",
      "9   city      Sugar Land    3\n",
      "10  city   The Woodlands    3\n",
      "11  city            Katy    2\n",
      "12  city        Richmond    2\n",
      "13  city         Webster    2\n",
      "14  city         Baytown    1\n",
      "15  city          Crosby    1\n",
      "16  city     Friendswood    1\n",
      "17  city        Fulshear    1\n",
      "18  city         HOUSTON    1\n",
      "19  city       Hempstead    1\n",
      "20  city          Humble    1\n",
      "21  city  Jersey Village    1\n",
      "22  city        Katy, TX    1\n",
      "23  city    Kingwood, TX    1\n",
      "24  city        La Porte    1\n",
      "25  city     League City    1\n",
      "26  city       New Caney    1\n",
      "27  city    Pasadena, TX    1\n",
      "28  city        Pearland    1\n",
      "29  city          Porter    1\n",
      "30  city        Stafford    1\n",
      "31  city          Waller    1\n",
      "32  city       Woodlands    1\n"
     ]
    }
   ],
   "source": [
    "query = ''' select key, value, count(*) \n",
    "from nodetags \n",
    "where key = 'city'\n",
    "group by value\n",
    "order by count(*) desc\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common leisure buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0        1                 2        3    4\n",
      "0   5127141025  leisure             pitch  regular  248\n",
      "1   5077530823  leisure     swimming_pool  regular  148\n",
      "2   5261519506  leisure              park  regular  112\n",
      "3   5568038456  leisure        playground  regular   98\n",
      "4   4326460364  leisure            garden  regular   19\n",
      "5    246392936  leisure       golf_course  regular   14\n",
      "6    579668112  leisure              pool  regular   14\n",
      "7   4286971468  leisure     sports_centre  regular   12\n",
      "8   5385232658  leisure      picnic_table  regular   10\n",
      "9    374906618  leisure           stadium  regular    5\n",
      "10  5256216786  leisure    fitness_centre  regular    4\n",
      "11  3717930668  leisure           slipway  regular    3\n",
      "12   579765111  leisure          dog_park  regular    2\n",
      "13   465243944  leisure            common  regular    1\n",
      "14   260566717  leisure  disc_golf_course  regular    1\n",
      "15    86330818  leisure            marina  regular    1\n",
      "16   403909954  leisure              walk  regular    1\n",
      "17   431591959  leisure        water_park  regular    1\n"
     ]
    }
   ],
   "source": [
    "# What are leisure buildings?\n",
    "query = ''' select *, count(*) as count\n",
    "from (select * from waytags union all select * from nodetags) as subq\n",
    "group by value\n",
    "having key = 'leisure'\n",
    "order by count desc\n",
    "limit 40 \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Ideas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we've observed that node tags and way tags tend to be similar and hold similar pieces of information. It seems that some information may be split across the two tables such that if you were only querying from one, your result may be incomplete and results thus misleading. \n",
    "\n",
    "For example, searching for restaurants in an area by querying nodetags may lead you to overlook a choice if additional, unique restaurants were held in the waytags table instead. You may end up missing out on your favorite restaurant. \n",
    "\n",
    "To remedy this, you may try to fix the problem at data input, or combine both tables for your queries. \n",
    "\n",
    "At data input, additional instructions on creating data for organization can be provided to those contributing to OSM's data. Cycling through to rearrange data from one table to another would be long, tedious, and difficult. Depending on the query, combining tags from both ways and nodes should be sufficient to gather relevant data in the same place. \n",
    "\n",
    "Additionally, for further data analysis, it would be more beneficial to read through the possible values for tags first, which should be provided on the OSM wiki. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a view that combines way and node tags \n",
    "query = ''' create view alltags as select * from nodetags union all select * from waytags '''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0                1                                     2  \\\n",
      "0       151335252              ele                                    26   \n",
      "1       151335252       gnis:Class                       Populated Place   \n",
      "2       151335252      gnis:County                             Fort Bend   \n",
      "3       151335252  gnis:County_num                                   157   \n",
      "4       151335252    gnis:ST_alpha                                    TX   \n",
      "5       151335252      gnis:ST_num                                    48   \n",
      "6       151335252               id                               1347777   \n",
      "7       151335252      import_uuid  bb7269ee-502a-5391-8056-e3ce0e66489c   \n",
      "8       151335252            is_in           Fort Bend,Texas,Tex.,TX,USA   \n",
      "9       151335252             name                              Stafford   \n",
      "10      151335252            place                                hamlet   \n",
      "11      151341161              ele                                    20   \n",
      "12      151341161       gnis:Class                       Populated Place   \n",
      "13      151341161      gnis:County                                Harris   \n",
      "14      151341161  gnis:County_num                                   201   \n",
      "15      151341161    gnis:ST_alpha                                    TX   \n",
      "16      151341161      gnis:ST_num                                    48   \n",
      "17      151341161               id                               1358415   \n",
      "18      151341161      import_uuid  bb7269ee-502a-5391-8056-e3ce0e66489c   \n",
      "19      151341161            is_in              Harris,Texas,Tex.,TX,USA   \n",
      "20      151341161             name                     Greenwood Village   \n",
      "21      151341161            place                                hamlet   \n",
      "22      151352050       population                             3549;2006   \n",
      "23      151352050              ele                                     1   \n",
      "24      151352050       gnis:Class                       Populated Place   \n",
      "25      151352050      gnis:County                                Harris   \n",
      "26      151352050  gnis:County_num                                   201   \n",
      "27      151352050    gnis:ST_alpha                                    TX   \n",
      "28      151352050      gnis:ST_num                                    48   \n",
      "29      151352050               id                               1377175   \n",
      "...           ...              ...                                   ...   \n",
      "187145  582017786            place                         neighbourhood   \n",
      "187146  582017797          natural                                  wood   \n",
      "187147  582021430          bicycle                                   yes   \n",
      "187148  582021430             foot                                   yes   \n",
      "187149  582021430          highway                               footway   \n",
      "187150  582109612          bicycle                                   yes   \n",
      "187151  582109612          highway                               footway   \n",
      "187152  582109612          surface                              concrete   \n",
      "187153  582229061           cables                                     3   \n",
      "187154  582229061         circuits                                     1   \n",
      "187155  582229061        frequency                                    60   \n",
      "187156  582229061             line                                busbar   \n",
      "187157  582229061            power                                  line   \n",
      "187158  582229061          voltage                                138000   \n",
      "187159  582229071           cables                                     3   \n",
      "187160  582229071         circuits                                     1   \n",
      "187161  582229071        frequency                                    60   \n",
      "187162  582229071            power                                  line   \n",
      "187163  582229071          voltage                                138000   \n",
      "187164  582229082           cables                                     3   \n",
      "187165  582229082         circuits                                     1   \n",
      "187166  582229082        frequency                                    60   \n",
      "187167  582229082             line                                busbar   \n",
      "187168  582229082            power                                  line   \n",
      "187169  582229082          voltage                                138000   \n",
      "187170  582229097           cables                                     3   \n",
      "187171  582229097         circuits                                     1   \n",
      "187172  582229097        frequency                                    60   \n",
      "187173  582229097            power                                  line   \n",
      "187174  582229097          voltage                                 69000   \n",
      "\n",
      "              3  \n",
      "0       regular  \n",
      "1       regular  \n",
      "2       regular  \n",
      "3       regular  \n",
      "4       regular  \n",
      "5       regular  \n",
      "6          gnis  \n",
      "7       regular  \n",
      "8       regular  \n",
      "9       regular  \n",
      "10      regular  \n",
      "11      regular  \n",
      "12      regular  \n",
      "13      regular  \n",
      "14      regular  \n",
      "15      regular  \n",
      "16      regular  \n",
      "17         gnis  \n",
      "18      regular  \n",
      "19      regular  \n",
      "20      regular  \n",
      "21      regular  \n",
      "22       census  \n",
      "23      regular  \n",
      "24      regular  \n",
      "25      regular  \n",
      "26      regular  \n",
      "27      regular  \n",
      "28      regular  \n",
      "29         gnis  \n",
      "...         ...  \n",
      "187145  regular  \n",
      "187146  regular  \n",
      "187147  regular  \n",
      "187148  regular  \n",
      "187149  regular  \n",
      "187150  regular  \n",
      "187151  regular  \n",
      "187152  regular  \n",
      "187153  regular  \n",
      "187154  regular  \n",
      "187155  regular  \n",
      "187156  regular  \n",
      "187157  regular  \n",
      "187158  regular  \n",
      "187159  regular  \n",
      "187160  regular  \n",
      "187161  regular  \n",
      "187162  regular  \n",
      "187163  regular  \n",
      "187164  regular  \n",
      "187165  regular  \n",
      "187166  regular  \n",
      "187167  regular  \n",
      "187168  regular  \n",
      "187169  regular  \n",
      "187170  regular  \n",
      "187171  regular  \n",
      "187172  regular  \n",
      "187173  regular  \n",
      "187174  regular  \n",
      "\n",
      "[187175 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# A quick query to make sure everything works accordingly \n",
    "query = ''' select * from alltags'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            0                1   2\n",
      "0                                 Whataburger           burger  16\n",
      "1                                      Subway         sandwich  12\n",
      "2                                  McDonald's           burger   8\n",
      "3                                     Wendy's           burger   8\n",
      "4                                 Chick-fil-A          chicken   6\n",
      "5                             Jack in the Box           burger   6\n",
      "6                                 Burger King           burger   5\n",
      "7                               Panda Express          chinese   4\n",
      "8                           Schlotzsky's Deli         sandwich   4\n",
      "9                                       Sonic           burger   3\n",
      "10                                Taco Cabana          mexican   3\n",
      "11                                   Chipotle          mexican   2\n",
      "12                            Jack In The Box           burger   2\n",
      "13                                Jamba Juice           drinks   2\n",
      "14                                        KFC          chicken   2\n",
      "15                            Little Caesar's            pizza   2\n",
      "16                                   Popeye's          chicken   2\n",
      "17                                   3 Chiles          mexican   1\n",
      "18                              Alamo Tamales          mexican   1\n",
      "19                              Alli Pizzeria            pizza   1\n",
      "20          Bahama Buck's Original Shaved Ice        ice_cream   1\n",
      "21                             Baskin-Robbins        ice_cream   1\n",
      "22                                Becks Prime           burger   1\n",
      "23                         Bombay Sweets Inc.           indian   1\n",
      "24                              Boston Market         american   1\n",
      "25                                   BreWingz            wings   1\n",
      "26                             Breakfast Klub  diner;breakfast   1\n",
      "27  California Pizza Kitchen at Huges Landing            pizza   1\n",
      "28                                  Carl's Jr           burger   1\n",
      "29                             Casa de Bravos          mexican   1\n",
      "..                                        ...              ...  ..\n",
      "59                              Midnite Slice            pizza   1\n",
      "60                               Mogul Indian           indian   1\n",
      "61                                  Mom Alone          mexican   1\n",
      "62                        Old Hickory Inn BBQ         barbecue   1\n",
      "63                               Olive Garden          italian   1\n",
      "64                               Patronella's          italian   1\n",
      "65                             Petrol Station     local;burger   1\n",
      "66                                  Pizza Hut            pizza   1\n",
      "67                     Popeye's Fried Chicken          chicken   1\n",
      "68                     Potbelly Sandwich Shop         sandwich   1\n",
      "69                                     Puerto          mexican   1\n",
      "70                          Relish Fine Foods         sandwich   1\n",
      "71                           Sam's Deli Diner           burger   1\n",
      "72                                 Simply Pho       vietnamese   1\n",
      "73                                Smashburger           burger   1\n",
      "74                Southwell's Hamburger Grill           burger   1\n",
      "75                                 Star Pizza            pizza   1\n",
      "76                  Straight Off The Road BBQ         barbeque   1\n",
      "77                                 Sushi Raku            sushi   1\n",
      "78                                  Taco Bell          mexican   1\n",
      "79                                 Thai Spice             thai   1\n",
      "80                              The Mason Jar         american   1\n",
      "81                      Tony's New York Pizza            pizza   1\n",
      "82                               Tutti Frutti        ice_cream   1\n",
      "83                                Villa Capri          italian   1\n",
      "84                                     Wendys           burger   1\n",
      "85                                  Wing-Stop            wings   1\n",
      "86                                      Xochi   Oaxaca;mexican   1\n",
      "87                                 Yokohamaya         japanese   1\n",
      "88                           green seed vegan            vegan   1\n",
      "\n",
      "[89 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# What are the most prevalent restaurants in the area? \n",
    "# Note, this query draws from alltags \n",
    "query = ''' select names.name, value, count (*) as count \n",
    "from \n",
    "alltags, \n",
    "(SELECT distinct(id) as restid FROM alltags WHERE value= 'restaurant' or value= 'fast_food') \n",
    "as rest, \n",
    "(select value as name, id as nameid from alltags where key = 'name') as names \n",
    "\n",
    "where alltags.id = rest.restid \n",
    "and alltags.id = names.nameid \n",
    "and alltags.key = 'cuisine' \n",
    "\n",
    "group by name \n",
    "order by count desc \n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon assessment, it seems that for data collected by humans, it is fairly consistent and thorough (at least more than expected). While this project was challenging, the OSM data seems like a valuable resource for compiling data and practicing data manipulation. \n",
    "\n",
    "Most of my frustrations actually occured with preparing the database and creating the database from the csv files. \n",
    "\n",
    "If our purpose was to clean the OSM data, then I would likely approach this differently in the future. To reiterate a point from earlier, I thought it better to correct mistakes rather than create a standardization with manmade (ish) data. Instead of standardizing something in one subset of data which may be different in another (depending on the auditor's preference i.e. highway vs hwy), it may be better to compile the various ways contributors may add a data point (Road vs Rd vs Rd.) and group them under the same category when analyzing the data\n",
    "\n",
    "More familiarization is likely needed with the OSM standards in terms of data possibilities (tags) and organization for other projects. However, many of the top contributors can likely share their code with contributors in other areas in order to speed up the process of preparing and cleaning. \n",
    "\n",
    "It seems the challenges faced with this dataset had numerous ways (ha) of being approached, and it would be interesting to see how the top contributors structure their bots to clean the data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Relevent resources utilized for major roadblocks that occured. \n",
    "\n",
    "https://discussions.udacity.com/t/creating-db-file-from-csv-files-with-non-ascii-unicode-characters/174958/7\n",
    "https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Udacity code for creating a sample file\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"some_osm.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "    output.write('</osm>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
